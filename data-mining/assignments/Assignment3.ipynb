{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "365a8b95-17fb-4995-be1a-00de66f0d74c",
   "metadata": {},
   "source": [
    "# Part 2: Ames Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ddb5d0f-879c-4d28-9900-262269c64c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ames = pd.read_csv(r'/Users/xnxk040/Library/CloudStorage/OneDrive-W.WGrainger,inc/Desktop/data mining data/AmesHousing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b3a1b-b629-4d3b-b384-e2ce4b3b0478",
   "metadata": {},
   "source": [
    "## 1. Split Samples into Sizes 70% and 30%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f31998-76a0-4b73-bba3-23540e74393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames70, ames30 = train_test_split(ames,test_size = 30, random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc926c3b-be8d-4d17-8031-75ccf0657dbd",
   "metadata": {},
   "source": [
    "## 2. Perform principal components of numeric variables from the Ames Housing Data on the training sample.\n",
    "1. Standardize your data so that each variable has mean = 0 and variance = 1\n",
    "2. Scale the test set using the mean and standard deviation of the training set. See \"Assignment 2 Steps\" for the code. This will help prevent information from “leaking” into the test set. Let’s be rigorous :)\n",
    "3. Perform PCA on the train data. Use princomp (R) and PCA (Python) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e22af8-bf17-49bf-8538-cc60bc225075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7f6aa8-11a4-4579-94d3-166757108698",
   "metadata": {},
   "source": [
    "## 3. Generate Scree Plots and select number of components you would retain.\n",
    "1. Display cumulative sum of variance accounted for by each additional PCA factor.  (VAF = cumsum(Train_PCA$sdev^2/sum(Train.PCA$sdev^2)))(R) and Train_PCA.explained_variance_ratio_(Python)\n",
    "2. Apply the \"elbow rule\" to decide how many components you'd like to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9235f0-bb5d-4b71-9756-4b5d693eeb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eefd051-f18a-4423-afc8-e3b444a1f814",
   "metadata": {},
   "source": [
    "## 4. Plot Component 1 loadings (x-axis) versus Component 2 loadings (y-axis). Use this plot to interpret and name the Components. Repeat this by plotting Component (1) separately versus all components you decided to retain from Step 3 (Component 3, Component 4 etc). Can you interpret each of the components you decide to retain? In case a component is not interpretable, note that.\n",
    "1. Plot loading 1 against all of the other loadings (6 pairwise comparisons). The right and top axis will be the value of loadings, the bottom and left access will be factor scores and the variables will be data points. Can also include specific observations. In the code below, Train_PCA​Loadings sets the first two loadings (i.e. coefficients) on the axis. What insights can we draw from these plots? Remember factor scores are like our new variables and loadings are our coefficients.\n",
    "    1. Python: biplot examples - https://medium.com/@bioturing/how-to-read-pca-biplots-and-scree-plots-186246aae063 (Links to an external site.)Links to an external site.;\n",
    "    2. code - https://stackoverflow.com/questions/39216897/plot-pca-loadings-and-loading-in-biplot-in-sklearn-like-rs-autoplot (Links to an external site.)Links to an external site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207cb8b-cd01-437a-bf5e-64240c3d8b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f1f7b-75cd-4692-8735-1a6f082933e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3de87eaf-c45c-4e9f-b653-bf6014d45ced",
   "metadata": {},
   "source": [
    "Perform the following:\n",
    "   1. Show that Component loadings are orthogonal. *If X is an orthogonal matrix, the t(X) %*% X is a diagonal matrix that has non-zero values on the diagonal and zeroes off the diagonal.*\n",
    "   2. Show that Component scores are orthogonal.\n",
    "   3. Perform Test validation of Principal Components solution.\n",
    "       1. predict the component scores in the Test using the predict() function in R and transform function in Python\n",
    "       2. matrix multiply the predicted component scores from (1) above with transpose of component loadings you derived from training data set from Step 2 above. Refer to Page 52 of Class Lecture for Session 4 for details. [Use the number of components you choose in step 3]\n",
    "        - *This step restores the features from the predicted principal components. Remember “Data = Components * t(Loadings)”. Since we’re using a subset of components, the restored features are expected to capture less variance than the original features.*\n",
    "       3. Compute the Variance Account For (R2) in the Test sample. That yields a measure of Test performance. [Use the number of components you choose in step 3. Your R^2 should be similar as that on the training set]\n",
    "           - 2 methods:\n",
    "               1. Cor(as.vector(test.set),as.vector(manual.test))^2\n",
    "               2. use R square formula: 1 – SS Error/SS Total. When calculating SS Error and SS Total, simply add up the metrics for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460597a2-0809-42aa-aa61-4b5127c0c85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
